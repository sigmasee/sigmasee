// Code generated by sigmaseectl, DO NOT EDIT.

package v1

import (
	"context"
	"encoding/base64"
	"fmt"
	"time"

	"github.com/aws/aws-lambda-go/events"
	"github.com/sigmasee/sigmasee/shared/enterprise/configuration"
	enterprisecontext "github.com/sigmasee/sigmasee/shared/enterprise/context"
	"github.com/sigmasee/sigmasee/shared/enterprise/messaging"
	"github.com/sigmasee/sigmasee/shared/enterprise/messaging/schemaregistry"
	"go.uber.org/zap"
	"google.golang.org/protobuf/proto"
)

type AwsLambdaConsumer interface {
	Handle(ctx context.Context, kafkaEvent events.KafkaEvent) error
}

type awsLambdaConsumer struct {
	logger          *zap.SugaredLogger
	appConfig       configuration.AppConfig
	contextHelper   enterprisecontext.ContextHelper
	awsLambdaConfig configuration.AwsLambdaConfig
	subscriber      Subscriber
	messageProducer messaging.MessageProducer
}

func NewAwsLambdaConsumer(
	logger *zap.SugaredLogger,
	appConfig configuration.AppConfig,
	contextHelper enterprisecontext.ContextHelper,
	awsLambdaConfig configuration.AwsLambdaConfig,
	subscriber Subscriber,
	messageProducer messaging.MessageProducer) AwsLambdaConsumer {
	return &awsLambdaConsumer{
		logger:          logger,
		appConfig:       appConfig,
		contextHelper:   contextHelper,
		awsLambdaConfig: awsLambdaConfig,
		subscriber:      subscriber,
		messageProducer: messageProducer,
	}
}

func (s *awsLambdaConsumer) Handle(ctx context.Context, kafkaEvent events.KafkaEvent) error {
	for _, records := range kafkaEvent.Records {
		for _, record := range records {
			if err := s.handleRecord(ctx, record); err != nil {
				return err
			}
		}
	}

	return nil
}

func (s *awsLambdaConsumer) handleRecord(ctx context.Context, record events.KafkaRecord) (err error) {
	if len(record.Value) == 0 {
		s.logger.Error("Received record Value is empty.")

		return nil
	}

	headers := s.getHeaders(record)
	if header, ok := headers[consumerGroupHeaderKey]; ok {
		if string(header) != s.appConfig.GetSource() {
			return nil
		}
	}

	payload, err := base64.StdEncoding.DecodeString(record.Value)
	if err != nil {
		s.logger.Errorf("error decoding base64 payload. Error: %v", err)

		return nil
	}

	if len(schemaregistry.ReservedHeaders) >= len(payload) {
		return s.logAndMoveToDeadLetterTopic(
			ctx,
			record,
			payload,
			"missing the schema metadata")
	}

	if payload[0] != 0 {
		return s.logAndMoveToDeadLetterTopic(
			ctx,
			record,
			payload,
			"message does not start with magic byte")
	}

	event := Event{}
	if err := proto.Unmarshal(payload[len(schemaregistry.ReservedHeaders):], &event); err != nil {
		return s.logAndMoveToDeadLetterTopic(
			ctx,
			record,
			payload,
			fmt.Sprintf("Failed to de-serialize Event message. Error: %v", err))
	}

	ctx = s.contextHelper.WithCorrelationId(ctx, event.Metadata.CorrelationId)

	start := time.Now()
	defer func(start time.Time) {
		s.logger.Infof("Handle event from Topic: %s - Event Type: %d, Execution time: %s. Error: %v", record.Topic, event.Metadata.Type, time.Since(start), err)
	}(start)

	defer func() {
		if r := recover(); r != nil {
			err = s.logAndMoveToDeadLetterTopic(
				ctx,
				record,
				payload,
				fmt.Sprintf("Recovered from panic state. Event message. Error: %v", r))
		}
	}()

	if err = s.subscriber.Handle(ctx, record.Topic, []byte(record.Key), headers, &event); err != nil {
		if RetryTopicNameCount == 0 {
			err = s.logAndMoveToDeadLetterTopic(
				ctx,
				record,
				payload,
				fmt.Sprintf("Failed to handle Event message. Error: %v", err))
		} else {
			if s.awsLambdaConfig.IsRetryTopic {
				index := s.awsLambdaConfig.RetryTopicIndex + 1

				if index == RetryTopicNameCount {
					err = s.logAndMoveToDeadLetterTopic(
						ctx,
						record,
						payload,
						fmt.Sprintf("Failed to handle Event message. Error: %v", err))
				} else {
					err = s.logAndMoveToRetryTopic(
						ctx,
						record,
						payload,
						fmt.Sprintf("Failed to handle Event message. Error: %v", err),
						index)
				}
			} else {
				err = s.logAndMoveToRetryTopic(
					ctx,
					record,
					payload,
					fmt.Sprintf("Failed to handle Event message. Error: %v", err),
					0)
			}
		}
	}

	return
}

func (s *awsLambdaConsumer) getHeaders(record events.KafkaRecord) map[string][]byte {
	headers := make(map[string][]byte)
	for _, headers := range record.Headers {
		for key, value := range headers {
			headers[key] = value
		}
	}

	return headers
}

func (s *awsLambdaConsumer) logAndMoveToDeadLetterTopic(ctx context.Context, record events.KafkaRecord, payload []byte, errorMessage string) error {
	s.logger.Infof("Moving to dead letter topic: %s, Error message: %s", DeadLetterTopicName, errorMessage)

	message := messaging.Message{
		Topic:   DeadLetterTopicName,
		Key:     []byte(record.Key),
		Headers: s.getHeaders(record),
		Payload: payload,
	}

	message.Headers["error"] = []byte(errorMessage)
	message.Headers[consumerGroupHeaderKey] = []byte(s.appConfig.GetSource())

	if err := s.messageProducer.Produce(ctx, []messaging.Message{message}); err != nil {
		s.logger.Errorf("Failed to move message to dead letter topic: %s. Error: %v", DeadLetterTopicName, err)

		return err
	}

	return nil
}

func (s *awsLambdaConsumer) logAndMoveToRetryTopic(ctx context.Context, record events.KafkaRecord, payload []byte, errorMessage string, retryTopicIndex int) error {
	topicName := fmt.Sprintf("%s.%d", RetryTopicNamePrefix, retryTopicIndex)

	s.logger.Infof("Moving to topic: %s, Error message: %s", topicName, errorMessage)

	message := messaging.Message{
		Topic:   topicName,
		Key:     []byte(record.Key),
		Headers: s.getHeaders(record),
		Payload: payload,
	}

	message.Headers["error"] = []byte(errorMessage)
	message.Headers[consumerGroupHeaderKey] = []byte(s.appConfig.GetSource())

	if err := s.messageProducer.Produce(ctx, []messaging.Message{message}); err != nil {
		s.logger.Errorf("Failed to move message to retry topic: %s. Error: %v", topicName, err)

		return err
	}

	return nil
}
